
# B站视频文本挖掘与分析项目

## 一、项目概述
本项目基于B站多分区视频的评论与弹幕数据，运用文本挖掘、自然语言处理（NLP）及机器学习技术，分析用户情感倾向、主题分布、高频词关联及分类算法性能，为内容创作与平台运营提供数据支持。

## 二、技术架构
### 数据采集
- **工具**：Python + Selenium + Requests  
- **技术**：  
  - 通过Selenium模拟浏览器行为获取热门视频BV号（`HotBvScraper.py`）。  
  - 使用Requests调用B站API，结合JS逆向技术破解评论数据加密（`CommentScraper.py`）。  
  - 利用B站官方接口直接获取弹幕数据（`DanmakuScraper.py`）。  

### 数据处理与分析
- **预处理**：  
  - 分词：Jieba分词 + 用户自定义词典。  
  - 清洗：去除停用词、特殊符号及无效字符。  
- **核心技术**：  
  - **情感分析**：SnowNLP库计算情感得分，区分积极/中性/消极评论。  
  - **主题建模**：LDA算法提取各分区潜在主题（如科技区聚焦“显卡”“火箭”，娱乐区关注“明星”“综艺”）。  
  - **关联规则**：Apriori算法挖掘高频词组合（如音乐区“听-感觉”强关联）。  
  - **分类算法**：对比LR、SVM、KNN等算法准确率，优化参数提升分类性能。  

### 可视化与输出
- **词云图**：Matplotlib + WordCloud展示各分区高频词汇。  
- **统计图表**：分区情感分布、主题关键词频率对比。  
- **结果存储**：JSON格式保存原始数据，CSV存储清洗后文本。  

## 三、文件结构
```
.
├── 数据采集脚本
│   ├── HotBvScraper.py    # 热门视频BV号获取
│   ├── CommentScraper.py  # 评论数据爬取（含JS逆向）
│   └── DanmakuScraper.py  # 弹幕数据爬取（官方接口）
├── 数据处理与分析脚本
│   ├── main.py           # 主流程调度（采集+分析）
│   ├── 分词去除停用词-词云图.ipynb  # 预处理与词云生成
│   ├── 情感分析.ipynb    # SnowNLP情感计算
│   ├── 文本主题建模.ipynb # LDA主题提取
│   ├── 关联规则算法.ipynb  # Apriori高频词组合挖掘
│   ├── 分类.ipynb        # 多算法分类对比
│   └── 聚类.ipynb        # KMeans文本聚类
├── 输出结果
│   ├── hot_videos_bv.json    # 各分区热门视频BV号
│   ├── video_info_*.json     # 分区视频评论/弹幕原始数据
│   └── processed_data.csv    # 清洗后文本数据
└── 依赖环境.txt              # 所需Python库列表
```

## 四、运行指南
### 环境依赖
- **Python版本**：3.8+  
- **关键库**：  
  ```python
  selenium==4.9.1    # 浏览器自动化
  requests==2.31.0   # HTTP请求
  jieba==0.42.1      # 中文分词
  snownlp==0.12.3    # 情感分析
  scikit-learn==1.3.2 # 机器学习
  mlxtend==0.22.0    # 关联规则挖掘
  wordcloud==1.9.2   # 词云图
  ```

### 步骤说明
1. **获取热门视频BV号**：  
   ```bash
   python HotBvScraper.py
   ```
   结果保存至`hot_videos_bv.json`。  

2. **爬取评论与弹幕**：  
   ```bash
   python main.py
   ```
   按分区爬取数据并保存为`video_info_*.json`。  

3. **数据预处理与分析**：  
   - 执行Jupyter Notebook脚本（如`分词去除停用词-词云图.ipynb`）进行清洗和可视化。  
   - 运行`分类.ipynb`等脚本进行算法训练与评估。  

## 五、项目亮点
- **多技术融合**：结合爬虫、NLP、机器学习，实现从数据采集到深度分析全流程覆盖。  
- **分区对比分析**：揭示游戏、影视、科技等15个分区在情感、主题、词汇上的显著差异。  
- **算法优化**：通过网格搜索调参，提升分类算法准确率（如MNB算法从0.27提升至0.55）。  

## 六、注意事项
- **数据合规**：仅用于学术研究，遵守B站API使用规范，避免过度爬取。  
- **参数调整**：根据实际需求修改`main.py`中的爬取数量（默认500条/视频）及算法参数。  

## 七、联系方式
如需协作或反馈问题，请通过GitHub Issues提交。  

---  
**作者**：[lotus116]  
**完成时间**：2024年12月  
**ps**:由于距离代码完成已经过去了很长时间，所以b站的w_rid加密规则可能已经改变，需要重新进行js逆向
